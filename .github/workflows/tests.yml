name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run tests
      run: |
        python run_tests.py --verbose
    
    - name: Generate coverage report
      run: |
        python run_tests.py --cov
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  benchmark:
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download previous benchmark results
      uses: dawidd6/action-download-artifact@v2
      continue-on-error: true
      with:
        workflow: tests.yml
        name: benchmark-results
        path: benchmarking_data/benchmarks
        if_no_artifact_found: ignore
    
    - name: Verify benchmark directory
      run: |
        mkdir -p benchmarking_data/benchmarks
        if [ -f benchmarking_data/benchmarks/benchmark_results.json ]; then
          echo "✓ Previous benchmark results found"
          runs=$(python -c "import json; print(len(json.load(open('benchmarking_data/benchmarks/benchmark_results.json'))))")
          echo "  Total runs in history: $runs"
        else
          echo "ℹ No previous results, starting fresh"
        fi
    
    - name: Run benchmarks
      run: |
        make benchmark-fast
    
    - name: Compare with previous results
      if: success()
      run: |
        python benchmark_demux.py --compare 5
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: |
          benchmarking_data/benchmarks/benchmark_results.json
          benchmarking_data/benchmarks/benchmark_report.md
        retention-days: 90
    
    - name: Comment benchmark results on commit
      if: success()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const { execSync } = require('child_process');
          
          // Generate summary using Python script
          const summary = execSync('python .github/scripts/benchmark_summary.py', { encoding: 'utf8' });
          
          github.rest.repos.createCommitComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            commit_sha: context.sha,
            body: summary
          });
